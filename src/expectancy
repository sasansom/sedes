#!/usr/bin/env python3

# Computes expectancy z-scores for unique values of grouping variables in input
# produced by tei2csv.
#
# Usage:
#   expectancy corpus/*.csv > expectancy.csv
#
# Expectancy is computed relative to two sets of grouping variables: The
# "distribution variables" and the "condition variables". The input is first
# partitioned into separate subsets according to distinct values of the
# condition variables. Then, within each subset, expectancy is computed
# according to the counts of distinct values of the distribution variables.
#
# You can control the condition variables and distribution variables with the
# --by option. The default value of the option is "sedes/lemma". The format is
# a comma-separated list of distribution variables on the left, then a slash
# character, then a comma-separated list of condition variables on the right.
# Use a backslash to escape commas, slashes, and backslashes in variable names.
#
# This command line is equivalent to the default:
#   expectancy --by sedes/lemma corpus/*.csv
# This command will get the expectancy of lemmata within each book of each work:
#   expectancy --by lemma/work,book_n corpus/*.csv
# The list of variables before or after the slash may be empty, which means that
# every input row should be considered equivalent according to that set. If the
# slash is omitted, it means the list of condition variables is empty. For
# example, these two equivalent commands get the overall sedes expectancy,
# without first partitioning by lemma or any other variable:
#   expectancy --by sedes/ corpus/*.csv
#   expectancy --by sedes corpus/*.csv
#
# Writes CSV to standard output. The columns are the names of the grouping
# variables, plus two more:
#   x: The number of times this lemma/sedes pair appears
#   z: The expectancy score, weighted as if each x value were repeated x times.

import csv
import getopt
import math
import sys

import common

def usage(file=sys.stdout):
    print(f"""\
Usage: {sys.argv[0]} [OPTIONS...] [INPUT.csv...] > OUTPUT.csv

Computes expectancy z-scores for unique values of grouping variables
(by default lemma and sedes) found in the corpus of INPUT.csv files.
The INPUT.csv files are the output of tei2csv.

Use the --by option to control the variables according to which
expectancy is computed. The default value of --by is "sedes/lemma". The
syntax is a comma-separated list of "distribution variables" on the
left, then a slash, then a comma-separated list of "condition variables"
on the right. Use a backslash to escape commas, slashes, and backslashes
in variable names.

The input is first partitioned into groups according to unique values of
the condition variables. Then, within each group, expectancy is computed
according to distinct values of the distribution variables.

  --by DIST_VARS.../COND_VARS...
              Set the grouping variables according to which expectancy
              is computed. Default: "sedes/lemma".
  -h, --help  Show this help.
""", end="", file=file)

# Return the mean of the sequence that arises from repeating each element e of
# x, e times.
def weighted_mean(x):
    return sum(e*e for e in x) / sum(x)

# Weighted population standard deviation, as in weighted_mean.
def weighted_sd_pop(x):
    μ = weighted_mean(x)
    return math.sqrt(sum(e*(e - μ)**2 for e in x) / sum(x))

# We special-case certain column names to transform their contained values on
# input.
INPUT_TRANSFORMS = {
    # Parse numeric sedes if present, otherwise set to None.
    "sedes": lambda val, row: float(val) if val else None,
}

def read_input(f):
    rows = []
    r = csv.DictReader(f)
    for row in r:
        for k in row:
            f = INPUT_TRANSFORMS.get(k)
            if f is not None:
                row[k] = f(row[k], row)
        rows.append(row)
    return rows

# Yields contiguous slices of x that are equal in fieldnames, along with a tuple
# containing the values that fieldnames maps to for the group.
def group_by(x, *fieldnames):
    i = 0
    j = 0
    prev_key = None
    for row in x:
        key = tuple(row[fieldname] for fieldname in fieldnames)
        if prev_key is not None and key != prev_key:
            yield prev_key, x[i:j]
            i = j
        prev_key = key
        j += 1
    yield key, x[i:]

def unique(a):
    result = []
    for x in a:
        if x not in result:
            result.append(x)
    return tuple(result)

# Special treatment for certain columns with certain names before writing to
# CSV.
OUTPUT_TRANSFORMS = {
    # Remove trailing ".0" from integer sedes.
    "sedes": lambda val: "{:g}".format(val) if val is not None else "",
    # Always add a sign and keep fractional digits in z.
    "z": lambda val: "{:+.15g}".format(val),
}

# Has the side effect of sorting input by the variables in
# dist_vars + cond_vars.
def process(input, output, dist_vars, cond_vars):
    expectancy = []

    # Sort input so elements that are identical in cond_vars+dist_vars are
    # contiguous.
    #
    # Values (in particular sedes) may be None, so add a None-checking guard
    # before each one, in order to avoid comparing NoneType to float, for
    # example.
    input.sort(key = lambda row:
        tuple(x for v in cond_vars + dist_vars for x in (row[v] is not None, row[v]))
    )

    # Count unique cond_vars+dist_vars tuples.
    for vals, group in group_by(input, *unique(cond_vars + dist_vars)):
        expectancy.append(dict(
            zip(unique(cond_vars + dist_vars), vals),
            x = len(group),
        ))

    for _, group in group_by(expectancy, *cond_vars):
        xvec = [inst["x"] for inst in group]
        μ = weighted_mean(xvec)
        σ = weighted_sd_pop(xvec)
        for inst in group:
            x = inst["x"]
            if σ != 0:
                inst["z"] = (x - μ) / σ

    # Run OUTPUT_TRANSFORMS on each row.
    for row in expectancy:
        for k in row:
            f = OUTPUT_TRANSFORMS.get(k)
            if f is not None:
                row[k] = f(row[k])

    output = csv.DictWriter(output, unique(cond_vars + dist_vars) + (
        "x",
        "z",
    ), lineterminator="\n")
    output.writeheader()
    output.writerows(expectancy)

def main():
    # Default grouping variables if not specified with --by.
    dist_cond_vars_spec = common.DEFAULT_DIST_COND_VARS_SPEC

    opts, filenames = getopt.gnu_getopt(sys.argv[1:], "h", (
        "by=",
        "help",
    ))
    for o, a in opts:
        if o == "--by":
            dist_cond_vars_spec = a
        elif o in ("-h", "--help"):
            usage()
            sys.exit(0)

    try:
        dist_vars, cond_vars = common.parse_dist_cond_vars_spec(dist_cond_vars_spec)
    except ValueError as e:
        print(f"error parsing --by specification {dist_cond_vars_spec!r}: {e}")
        sys.exit(1)

    input = []
    for filename in filenames:
        with open(filename) as f:
            input.extend(read_input(f))

    process(input, sys.stdout, dist_vars, cond_vars)

if __name__ == "__main__":
    main()
