#!/usr/bin/env python3

# Extracts words and their sedes from a TEI XML document and writes the words to
# standard output as CSV, one row per word.
#
# Usage:
#   tei2csv IDENTIFIER FILENAME.xml > FILENAME.csv
# IDENTIFIER is a short text identifier for the work that will be copied to the
# output; e.g., "Il.". FILENAME.xml is the name of the XML document containing
# the text of the work.

import csv
import getopt
import re
import sys

import lemma as lemma_mod
import sedes
import tei

def usage(file=sys.stdout):
    print(f"""\
Usage: {sys.argv[0]} IDENTIFIER FILENAME.xml > FILENAME.csv

IDENTIFIER is a short text identifier for the work; e.g., "Il.".
FILENAME.XML is a TEI XML document containing the text of the work.
""", end="", file=file)

def assign_sedes_for_line(line):
    """From a line, return a sequence of (word, word_n, sedes, metrical_shape, num_scansions, tone_shape)
    tuples. sedes will be non-blank if and only if num_scansions is equal to 1."""
    assignments = sedes.analyze(line.text_without_quotes())
    if len(assignments) == 1:
        return tuple((word, word_n, sedes, metrical_shape, len(assignments), tone_shape) for (word, word_n, sedes, metrical_shape, tone_shape) in assignments[0])
    else:
        # If no scansions or multiple scansions, output "".
        return tuple((word, word_n+1, "", "", len(assignments), "") for (word_n, word) in enumerate(line.words()))

def process(f, work_identifier):
    seen_lines = set()
    doc = tei.TEI(f)
    for loc, line in doc.lines():
        if (loc.book_n, loc.line_n) in seen_lines:
            print(f"warning: {work_identifier}: duplicate line {loc!r}", file=sys.stderr)
        seen_lines.add((loc.book_n, loc.line_n))
        # print(repr(line.text()))
        # print(repr(line.text_without_quotes()))
        if line.text_without_quotes() in sedes.KNOWN_SCANSIONS:
            scanned = "manual"
        else:
            scanned = "auto"
        for entry in assign_sedes_for_line(line):
            word, word_n, pos, metrical_shape, num_scansions, tone_shape = entry
            lemma = lemma_mod.lookup(word, (work_identifier, loc.book_n, loc.line_n, word_n))
            if lemma is None:
                lemma = word # Use the word itself as lemma if lemmatization fails.
            yield {
                "work": work_identifier,
                "book_n": loc.book_n,
                "line_n": loc.line_n,
                "word_n": word_n,
                "word": word,
                "scanned": scanned,
                "num_scansions": num_scansions,
                "sedes": pos,
                "metrical_shape": metrical_shape,
                "tone_shape": tone_shape,
                "lemma": lemma,
                "line_text": line.text(),
            }

def main():
    opts, args = getopt.gnu_getopt(sys.argv[1:], "h", ["help"])
    for o, a in opts:
        if o in ("-h", "--help"):
            usage()
            sys.exit(0)

    try:
        work_identifier, input_filename = args
    except ValueError:
        print("error: usage error", file=sys.stderr)
        print(file=sys.stderr)
        usage(sys.stderr)
        sys.exit(1)

    csv_w = csv.DictWriter(
        sys.stdout,
        [
            "work",
            "book_n",
            "line_n",
            "word_n",
            "word",
            "lemma",
            "sedes",
            "metrical_shape",
            "scanned",
            "num_scansions",
            "tone_shape",
            "line_text",
        ],
        lineterminator="\n",
    )
    csv_w.writeheader()
    with open(input_filename) as f:
        for row in process(f, work_identifier):
            csv_w.writerow(row)

if __name__ == "__main__":
    main()
